{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7e09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import albumentations as A\n",
    "import albumentations.augmentations.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from models import *\n",
    "from watermarkDataset import WatermarkDataset\n",
    "from vgg_loss import VGG19, VGG11\n",
    "from utils import sample_images, val_loss, concat_images\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03d23db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 3e-4\n",
    "betas = (0.5, 0.999)\n",
    "batch_size = 6\n",
    "n_cpu = 6\n",
    "start_epoch = 0\n",
    "load = False\n",
    "epochs = 500\n",
    "sample_interval = 500\n",
    "checkpoint_interval = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mean = (0.6349, 0.5809, 0.5312)\n",
    "std = (0.3283, 0.3288, 0.3534)\n",
    "# Loss weight of L1 pixel-wise loss between translated image and real image\n",
    "lambda_pixel = 100 \n",
    "lambda_vgg = 1000\n",
    "# Calculate output of image discriminator (PatchGAN)\n",
    "kernel_size=256\n",
    "patch = (1, kernel_size // 2 ** 4, kernel_size // 2 ** 4)\n",
    "unfold = nn.Unfold(kernel_size=(kernel_size, kernel_size), stride=(kernel_size,kernel_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15bb598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "train_transform = A.Compose([\n",
    "        A.RandomCrop(width=kernel_size, height=kernel_size),\n",
    "        #A.augmentations.transforms.Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        ToTensorV2(),\n",
    "        ],  \n",
    "        additional_targets={'image1': 'image'}\n",
    "    )\n",
    "\n",
    "val_transform = A.Compose([\n",
    "        #A.augmentations.transforms.Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(),\n",
    "        ],  \n",
    "        additional_targets={'image1': 'image'}\n",
    "    )\n",
    "inv_normalize = transforms.Normalize(\n",
    "   mean= [-m/s for m, s in zip(mean, std)],\n",
    "   std= [1/s for s in std]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbf4734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_pixelwise = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c907fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize generator and discriminator\n",
    "generator = GeneratorUNet().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "if load:\n",
    "    generator.load_state_dict(torch.load(\"saved_models/%s/generator_%d.pth\" % (\"watermarkdataset\", start_epoch)))\n",
    "    discriminator.load_state_dict(torch.load(\"saved_models/%s/discriminator_%d.pth\" % (\"watermarkdataset\", start_epoch)))\n",
    "else:\n",
    "    # Initialize weights\n",
    "    generator.apply(weights_init_normal)\n",
    "    discriminator.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a80a8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=betas)\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7a915ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr scheduler\n",
    "lrs_G = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_G, \"min\", verbose=True)\n",
    "lrs_D = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_D, \"min\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1482d4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset and dataloader\n",
    "train = WatermarkDataset(\"data/train\", transform=train_transform)\n",
    "trainloader = DataLoader(\n",
    "    train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=n_cpu,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val = WatermarkDataset(\"data/valid\", transform=val_transform)\n",
    "valloader = DataLoader(\n",
    "    val,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74abcbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498f7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_scaler = torch.cuda.amp.GradScaler()\n",
    "d_scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8618387",
   "metadata": {},
   "outputs": [],
   "source": [
    "vggloss = VGG11()\n",
    "vggloss = vggloss.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13f1779",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prev_time = time.time()\n",
    "if start_epoch == 0:\n",
    "    start_epoch = -1\n",
    "for epoch in range(start_epoch+1, epochs):\n",
    "    loop = tqdm(trainloader)\n",
    "    for i, batch in enumerate(loop):\n",
    "        \n",
    "        if i > 5:\n",
    "            continue\n",
    "        # Model inputs\n",
    "        real_A = Variable(batch[0].type(Tensor)).to(device)\n",
    "        real_B = Variable(batch[1].type(Tensor)).to(device)\n",
    "        \n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(np.ones((real_A.size(0), *patch))), requires_grad=False).to(device)\n",
    "        fake = Variable(Tensor(np.zeros((real_A.size(0), *patch))), requires_grad=False).to(device)\n",
    "\n",
    "        # ------------------\n",
    "        #  Train Generators\n",
    "        # ------------------\n",
    "        optimizer_G.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # GAN loss\n",
    "            fake_B = generator(real_A)\n",
    "            pred_fake = discriminator(fake_B, real_A)\n",
    "            loss_GAN = criterion_GAN(pred_fake, valid)\n",
    "            # Pixel-wise loss\n",
    "            loss_pixel = criterion_pixelwise(fake_B, real_B)\n",
    "\n",
    "            # Total loss\n",
    "            #print(f\"loss gan: {loss_GAN} loss pixel: {lambda_pixel * loss_pixel} loss vgg: {lambda_vgg*vggloss.calc_loss(fake_B, real_B)}\")\n",
    "            loss_G = loss_GAN + lambda_pixel * loss_pixel + lambda_vgg * vggloss.calc_loss(fake_B, real_B)\n",
    "            \n",
    "            g_scaler.scale(loss_G).backward()\n",
    "            g_scaler.step(optimizer_G)\n",
    "            g_scaler.update()\n",
    "        \n",
    "            \n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        optimizer_D.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # Real loss\n",
    "            pred_real = discriminator(real_B, real_A)\n",
    "            loss_real = criterion_GAN(pred_real, valid)\n",
    "\n",
    "            # Fake loss\n",
    "            pred_fake = discriminator(fake_B.detach(), real_A)\n",
    "            loss_fake = criterion_GAN(pred_fake, fake)\n",
    "\n",
    "            # Total loss\n",
    "            loss_D = 0.5 * (loss_real + loss_fake)\n",
    "\n",
    "            d_scaler.scale(loss_D).backward()\n",
    "            d_scaler.step(optimizer_D)\n",
    "            d_scaler.update()\n",
    "        \n",
    "        \n",
    "        # --------------\n",
    "        #  Log Progress\n",
    "        # --------------\n",
    "        loop.set_description(f\"epoch: {epoch} loss discriminator: {loss_D:.5f} loss generator: {loss_G:.5f}\")\n",
    "        \n",
    "\n",
    "        # If at sample interval save image\n",
    "        batches_done = epoch * len(trainloader) + i\n",
    "        if batches_done % sample_interval == 0:\n",
    "            sample_images(batches_done, 10, generator, valloader, Tensor, kernel_size, unfold, device)\n",
    "          \n",
    "    # check if lr should be updated\n",
    "    val_loss_G, val_loss_D = val_loss(generator, discriminator, vggloss, valloader, Tensor, kernel_size, unfold, patch, criterion_GAN, criterion_pixelwise, lambda_pixel, lambda_vgg, device)\n",
    "    print(f\"epoch {epoch} with G and D val loss:\", val_loss_G, val_loss_D)\n",
    "    lrs_D.step(val_loss_D)\n",
    "    lrs_G.step(val_loss_G)  \n",
    "    \n",
    "    # Save model checkpoints\n",
    "    if epoch % checkpoint_interval == 0:\n",
    "        torch.save(generator.state_dict(), \"saved_models/%s/generator_%d.pth\" % (\"watermarkdataset\", epoch))\n",
    "        torch.save(discriminator.state_dict(), \"saved_models/%s/discriminator_%d.pth\" % (\"watermarkdataset\", epoch))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
