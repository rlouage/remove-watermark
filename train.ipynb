{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d7e09ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import numpy as np\n",
    "import math\n",
    "import itertools\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torch.autograd import Variable\n",
    "import albumentations as A\n",
    "import albumentations.augmentations.functional as F\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "from models import *\n",
    "from watermarkDataset import WatermarkDataset\n",
    "from vgg_loss import VGG19, VGG11\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cb13ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove normalization and check results then\n",
    "# normalization makes images grey?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f03d23db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameters\n",
    "lr = 3e-4\n",
    "betas = (0.5, 0.999)\n",
    "batch_size = 6\n",
    "n_cpu = 6\n",
    "start_epoch = 100\n",
    "load = True\n",
    "epochs = 500\n",
    "sample_interval = 500\n",
    "checkpoint_interval = 1\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "mean = (0.6349, 0.5809, 0.5312)\n",
    "std = (0.3283, 0.3288, 0.3534)\n",
    "# Loss weight of L1 pixel-wise loss between translated image and real image\n",
    "lambda_pixel = 100 # was 100 orig\n",
    "lambda_vgg = 1000 # orig 1000\n",
    "# Calculate output of image discriminator (PatchGAN)\n",
    "patch = (1, 256 // 2 ** 4, 256 // 2 ** 4)\n",
    "kernel_size=256\n",
    "unfold = nn.Unfold(kernel_size=(kernel_size, kernel_size), stride=(kernel_size,kernel_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d15bb598",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms\n",
    "train_transform = A.Compose([\n",
    "        A.RandomCrop(width=kernel_size, height=kernel_size),\n",
    "        #A.augmentations.transforms.Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        ToTensorV2(),\n",
    "        ],  \n",
    "        additional_targets={'image1': 'image'}\n",
    "    )\n",
    "\n",
    "val_transform = A.Compose([\n",
    "        #A.augmentations.transforms.Normalize(mean=mean, std=std, max_pixel_value=255.0, p=1.0),\n",
    "        ToTensorV2(),\n",
    "        ],  \n",
    "        additional_targets={'image1': 'image'}\n",
    "    )\n",
    "inv_normalize = transforms.Normalize(\n",
    "   mean= [-m/s for m, s in zip(mean, std)],\n",
    "   std= [1/s for s in std]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e673244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def val_loss():\n",
    "    \"\"\" BATCHSIZE SHOULD BE 1 \"\"\"\n",
    "    generator.eval()\n",
    "    discriminator.eval()\n",
    "    vggloss.eval()\n",
    "    \n",
    "    total_loss_G = torch.zeros([1], dtype=torch.float).to(device)\n",
    "    total_loss_D = torch.zeros([1], dtype=torch.float).to(device)\n",
    "    loop = tqdm(valloader)\n",
    "    for i, batch in enumerate(loop):\n",
    "        # Model inputs\n",
    "        real_A = Variable(batch[0].type(Tensor))\n",
    "        real_B = Variable(batch[1].type(Tensor))\n",
    "        \n",
    "        # reshape full images to patches of 256x256\n",
    "        _,_,w,h = real_A.shape\n",
    "        real_A = transforms.functional.pad(real_A, [0, 0, int((int(h/kernel_size)+1)*kernel_size)-h, int((int(w/kernel_size)+1)*kernel_size)-w])\n",
    "        real_A = unfold(real_A).squeeze(0).T.view(-1,3,kernel_size,kernel_size)\n",
    "        _,_,w,h = real_A.shape\n",
    "        real_B = transforms.functional.pad(real_B, [0, 0, int((int(h/kernel_size)+1)*kernel_size)-h, int((int(w/kernel_size)+1)*kernel_size)-w])\n",
    "        real_B = unfold(real_B).squeeze(0).T.view(-1,3,kernel_size,kernel_size)\n",
    "        \n",
    "\n",
    "        # split data up in single images to fit in memory\n",
    "        b = real_A.shape[0]\n",
    "        t_loss_G = torch.zeros([1], dtype=torch.float).to(device)\n",
    "        t_loss_D = torch.zeros([1], dtype=torch.float).to(device)\n",
    "        \n",
    "        for k in range(b):\n",
    "            real_A_ = real_A[k].clone().unsqueeze(0).to(device)\n",
    "            real_B_ = real_B[k].clone().unsqueeze(0).to(device)\n",
    "            # Adversarial ground truths\n",
    "            valid = Variable(Tensor(np.ones((real_A_.size(0), *patch))), requires_grad=False).to(device)\n",
    "            fake = Variable(Tensor(np.zeros((real_A_.size(0), *patch))), requires_grad=False).to(device)\n",
    "            with torch.no_grad():\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    # Gen\n",
    "                    fake_B = generator(real_A_)\n",
    "                    pred_fake = discriminator(fake_B, real_A_)\n",
    "                    loss_GAN = criterion_GAN(pred_fake, valid)\n",
    "                    # Pixel-wise loss\n",
    "                    loss_pixel = criterion_pixelwise(fake_B, real_B_)\n",
    "                    # Total loss\n",
    "                    loss_G = loss_GAN + lambda_pixel * loss_pixel + lambda_vgg * vggloss.calc_loss(fake_B, real_B_)\n",
    "                    t_loss_G += loss_G\n",
    "\n",
    "                    # Disc\n",
    "                    pred_real = discriminator(real_B_, real_A_)\n",
    "                    loss_real = criterion_GAN(pred_real, valid)\n",
    "                    # Fake loss\n",
    "                    pred_fake = discriminator(fake_B.detach(), real_A_)\n",
    "                    loss_fake = criterion_GAN(pred_fake, fake)\n",
    "                    # Total loss\n",
    "                    loss_D = 0.5 * (loss_real + loss_fake)\n",
    "                    t_loss_D += loss_D\n",
    "                    \n",
    "        t_loss_G = t_loss_G/b\n",
    "        t_loss_D = t_loss_D/b\n",
    "        total_loss_G += t_loss_G\n",
    "        total_loss_D += t_loss_D\n",
    "                \n",
    "    total_loss_G = total_loss_G/len(valloader)\n",
    "    total_loss_D = total_loss_D/len(valloader)\n",
    "    \n",
    "    generator.train()\n",
    "    discriminator.train()\n",
    "    vggloss.train()\n",
    "    return total_loss_G,total_loss_D\n",
    "        \n",
    "def sample_images(batches_done, N):\n",
    "    \"\"\" Save the first N generated images from the dataset \"\"\"\n",
    "    generator.eval()\n",
    "    generator.to(\"cpu\")\n",
    "    \n",
    "    imgs = []\n",
    "    for i, batch in enumerate(valloader):\n",
    "        if i >= N:\n",
    "            break\n",
    "        t = []\n",
    "        real_A = Variable(batch[0].type(Tensor))\n",
    "        real_B = Variable(batch[1].type(Tensor))\n",
    "        t.append(real_A.detach())\n",
    "        \n",
    "        _,_,w,h = real_A.shape\n",
    "        real_A = transforms.functional.pad(real_A, [0, 0, int((int(h/kernel_size)+1)*kernel_size)-h, int((int(w/kernel_size)+1)*kernel_size)-w])\n",
    "        real_A = unfold(real_A).squeeze(0).T.view(-1,3,kernel_size,kernel_size)\n",
    "        fake_B = generator(real_A)\n",
    "        \n",
    "        new_w = int((int(w/kernel_size)+1)*kernel_size)\n",
    "        new_h = int((int(h/kernel_size)+1)*kernel_size)\n",
    "        fake_B = fake_B.permute(1,2,3,0)\n",
    "        fake_B = fake_B.reshape(1,3*kernel_size*kernel_size,fake_B.shape[3])\n",
    "        fold = nn.Fold((new_w,new_h), (kernel_size,kernel_size), stride=(kernel_size,kernel_size))\n",
    "        fake_B = fold(fake_B)\n",
    "        \n",
    "        fake_B = fake_B[:, :, 0:w, 0:h]\n",
    "        t.append(fake_B.detach())\n",
    "        t.append(real_B.detach())\n",
    "        imgs.append(tuple(t))\n",
    "    \n",
    "    os.mkdir(f\"images/watermarkdataset/{batches_done}\")\n",
    "    for j, (a,fb,b) in enumerate(imgs):\n",
    "        img_sample = torch.cat((a, fb, b), -2)\n",
    "        save_image(img_sample, f\"images/watermarkdataset/{batches_done}/{j}.jpg\")\n",
    "    \n",
    "    generator.to(device)\n",
    "    generator.train()\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8dbf4734",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "criterion_GAN = torch.nn.MSELoss()\n",
    "criterion_pixelwise = torch.nn.L1Loss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3c907fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize generator and discriminator\n",
    "generator = GeneratorUNet().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "if load:\n",
    "    generator.load_state_dict(torch.load(\"saved_models/%s/generator_%d.pth\" % (\"watermarkdataset\", start_epoch)))\n",
    "    discriminator.load_state_dict(torch.load(\"saved_models/%s/discriminator_%d.pth\" % (\"watermarkdataset\", start_epoch)))\n",
    "else:\n",
    "    # Initialize weights\n",
    "    generator.apply(weights_init_normal)\n",
    "    discriminator.apply(weights_init_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a80a8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizers\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), lr=3e-7, betas=betas)\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=3e-5, betas=betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e7a915ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr scheduler\n",
    "lrs_G = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_G, \"min\", verbose=True)\n",
    "lrs_D = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_D, \"min\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1482d4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset and dataloader\n",
    "train = WatermarkDataset(\"data/train\", transform=train_transform)\n",
    "trainloader = DataLoader(\n",
    "    train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=n_cpu,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "val = WatermarkDataset(\"data/valid\", transform=val_transform)\n",
    "valloader = DataLoader(\n",
    "    val,\n",
    "    batch_size=1,\n",
    "    shuffle=False,\n",
    "    num_workers=1,\n",
    "    pin_memory=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74abcbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Tensor = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "498f7fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_scaler = torch.cuda.amp.GradScaler()\n",
    "d_scaler = torch.cuda.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8618387",
   "metadata": {},
   "outputs": [],
   "source": [
    "vggloss = VGG11()\n",
    "vggloss = vggloss.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c13f1779",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 74 loss discriminator: 0.00092 loss generator: 3.23484: 100%|███████████████| 3500/3500 [47:30<00:00,  1.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:51<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74 with G and D val loss: tensor([2.7406], device='cuda:0') tensor([0.0220], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 75 loss discriminator: 0.00321 loss generator: 3.12376: 100%|███████████████| 3500/3500 [47:45<00:00,  1.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:51<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75 with G and D val loss: tensor([2.7480], device='cuda:0') tensor([0.0234], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 76 loss discriminator: 0.05467 loss generator: 3.37285: 100%|███████████████| 3500/3500 [47:35<00:00,  1.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:51<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76 with G and D val loss: tensor([2.6764], device='cuda:0') tensor([0.0260], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 77 loss discriminator: 0.01607 loss generator: 1.77585: 100%|███████████████| 3500/3500 [47:33<00:00,  1.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:51<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77 with G and D val loss: tensor([2.7538], device='cuda:0') tensor([0.0218], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 78 loss discriminator: 0.00112 loss generator: 4.63670: 100%|███████████████| 3500/3500 [47:32<00:00,  1.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:51<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78 with G and D val loss: tensor([2.7395], device='cuda:0') tensor([0.0222], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 79 loss discriminator: 0.00115 loss generator: 2.85737: 100%|███████████████| 3500/3500 [47:35<00:00,  1.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:51<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 79 with G and D val loss: tensor([2.7507], device='cuda:0') tensor([0.0263], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 80 loss discriminator: 0.00403 loss generator: 3.80876: 100%|███████████████| 3500/3500 [47:39<00:00,  1.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:51<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80 with G and D val loss: tensor([2.7690], device='cuda:0') tensor([0.0213], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 81 loss discriminator: 0.00110 loss generator: 2.60502: 100%|███████████████| 3500/3500 [47:42<00:00,  1.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:52<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81 with G and D val loss: tensor([2.7033], device='cuda:0') tensor([0.0232], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 82 loss discriminator: 0.00902 loss generator: 1.93335: 100%|███████████████| 3500/3500 [47:41<00:00,  1.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:54<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82 with G and D val loss: tensor([2.7166], device='cuda:0') tensor([0.0215], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 83 loss discriminator: 0.00317 loss generator: 2.13851: 100%|███████████████| 3500/3500 [47:47<00:00,  1.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:53<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83 with G and D val loss: tensor([2.7282], device='cuda:0') tensor([0.0215], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 84 loss discriminator: 0.00281 loss generator: 2.12442: 100%|███████████████| 3500/3500 [47:44<00:00,  1.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:54<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84 with G and D val loss: tensor([2.7227], device='cuda:0') tensor([0.0240], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 85 loss discriminator: 0.00192 loss generator: 1.90216: 100%|███████████████| 3500/3500 [47:45<00:00,  1.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:51<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85 with G and D val loss: tensor([2.7361], device='cuda:0') tensor([0.0234], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 86 loss discriminator: 0.08412 loss generator: 1.47916: 100%|███████████████| 3500/3500 [47:45<00:00,  1.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:56<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86 with G and D val loss: tensor([2.7320], device='cuda:0') tensor([0.0252], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 87 loss discriminator: 0.00321 loss generator: 2.42090: 100%|███████████████| 3500/3500 [48:02<00:00,  1.21it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:54<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87 with G and D val loss: tensor([2.6629], device='cuda:0') tensor([0.0288], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 88 loss discriminator: 0.00139 loss generator: 2.81890: 100%|███████████████| 3500/3500 [47:48<00:00,  1.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:54<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88 with G and D val loss: tensor([2.7652], device='cuda:0') tensor([0.0199], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 89 loss discriminator: 0.00182 loss generator: 2.72431: 100%|███████████████| 3500/3500 [47:26<00:00,  1.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:51<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89 with G and D val loss: tensor([2.7128], device='cuda:0') tensor([0.0212], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 90 loss discriminator: 0.00135 loss generator: 5.14628: 100%|███████████████| 3500/3500 [47:17<00:00,  1.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:51<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90 with G and D val loss: tensor([2.7522], device='cuda:0') tensor([0.0208], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 91 loss discriminator: 0.00111 loss generator: 3.12510: 100%|███████████████| 3500/3500 [47:35<00:00,  1.23it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:51<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91 with G and D val loss: tensor([2.7203], device='cuda:0') tensor([0.0211], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 92 loss discriminator: 0.00116 loss generator: 2.66758: 100%|███████████████| 3500/3500 [47:43<00:00,  1.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:51<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92 with G and D val loss: tensor([2.7370], device='cuda:0') tensor([0.0196], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 93 loss discriminator: 0.04936 loss generator: 1.76056: 100%|███████████████| 3500/3500 [47:47<00:00,  1.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:55<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93 with G and D val loss: tensor([2.7216], device='cuda:0') tensor([0.0201], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 94 loss discriminator: 0.00193 loss generator: 3.70896: 100%|███████████████| 3500/3500 [47:43<00:00,  1.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:51<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94 with G and D val loss: tensor([2.6958], device='cuda:0') tensor([0.0219], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 95 loss discriminator: 0.00348 loss generator: 3.35286: 100%|███████████████| 3500/3500 [47:42<00:00,  1.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:54<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95 with G and D val loss: tensor([2.7164], device='cuda:0') tensor([0.0218], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 96 loss discriminator: 0.00374 loss generator: 2.95530: 100%|███████████████| 3500/3500 [47:42<00:00,  1.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:53<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96 with G and D val loss: tensor([2.7466], device='cuda:0') tensor([0.0216], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 97 loss discriminator: 0.00156 loss generator: 3.85497: 100%|███████████████| 3500/3500 [47:41<00:00,  1.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:54<00:00,  1.85s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97 with G and D val loss: tensor([2.6875], device='cuda:0') tensor([0.0214], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 98 loss discriminator: 0.00525 loss generator: 11.30066: 100%|██████████████| 3500/3500 [47:42<00:00,  1.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:51<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98 with G and D val loss: tensor([2.7215], device='cuda:0') tensor([0.0209], device='cuda:0')\n",
      "Epoch    25: reducing learning rate of group 0 to 3.0000e-07.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 99 loss discriminator: 0.01572 loss generator: 2.85177: 100%|███████████████| 3500/3500 [47:42<00:00,  1.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:51<00:00,  1.84s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99 with G and D val loss: tensor([2.6768], device='cuda:0') tensor([0.0229], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 100 loss discriminator: 0.00547 loss generator: 1.64480: 100%|██████████████| 3500/3500 [47:48<00:00,  1.22it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████| 191/191 [05:55<00:00,  1.86s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 100 with G and D val loss: tensor([2.6952], device='cuda:0') tensor([0.0228], device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch: 101 loss discriminator: 0.00277 loss generator: 2.93362:  69%|█████████▋    | 2413/3500 [33:06<14:54,  1.21it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-4406875f46d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m             \u001b[0mg_scaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_G\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m             \u001b[0mg_scaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer_G\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m             \u001b[0mg_scaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rob\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[1;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 338\u001b[1;33m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"stage\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rob\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[1;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\rob\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\torch\\cuda\\amp\\grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_maybe_opt_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    283\u001b[0m         \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 284\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[1;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"found_inf_per_device\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    285\u001b[0m             \u001b[0mretval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    286\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "prev_time = time.time()\n",
    "if start_epoch == 0:\n",
    "    start_epoch = -1\n",
    "for epoch in range(start_epoch+1, epochs):\n",
    "    loop = tqdm(trainloader)\n",
    "    for i, batch in enumerate(loop):\n",
    "        \n",
    "        # Model inputs\n",
    "        real_A = Variable(batch[0].type(Tensor)).to(device)\n",
    "        real_B = Variable(batch[1].type(Tensor)).to(device)\n",
    "        \n",
    "        # Adversarial ground truths\n",
    "        valid = Variable(Tensor(np.ones((real_A.size(0), *patch))), requires_grad=False).to(device)\n",
    "        fake = Variable(Tensor(np.zeros((real_A.size(0), *patch))), requires_grad=False).to(device)\n",
    "\n",
    "        # ------------------\n",
    "        #  Train Generators\n",
    "        # ------------------\n",
    "        optimizer_G.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # GAN loss\n",
    "            fake_B = generator(real_A)\n",
    "            pred_fake = discriminator(fake_B, real_A)\n",
    "            loss_GAN = criterion_GAN(pred_fake, valid)\n",
    "            # Pixel-wise loss\n",
    "            loss_pixel = criterion_pixelwise(fake_B, real_B)\n",
    "\n",
    "            # Total loss\n",
    "            #print(f\"loss gan: {loss_GAN} loss pixel: {lambda_pixel * loss_pixel} loss vgg: {lambda_vgg*vggloss.calc_loss(fake_B, real_B)}\")\n",
    "            loss_G = loss_GAN + lambda_pixel * loss_pixel + lambda_vgg * vggloss.calc_loss(fake_B, real_B)\n",
    "            \n",
    "            g_scaler.scale(loss_G).backward()\n",
    "            g_scaler.step(optimizer_G)\n",
    "            g_scaler.update()\n",
    "        \n",
    "            \n",
    "        # ---------------------\n",
    "        #  Train Discriminator\n",
    "        # ---------------------\n",
    "        optimizer_D.zero_grad()\n",
    "        with torch.cuda.amp.autocast():\n",
    "            # Real loss\n",
    "            pred_real = discriminator(real_B, real_A)\n",
    "            loss_real = criterion_GAN(pred_real, valid)\n",
    "\n",
    "            # Fake loss\n",
    "            pred_fake = discriminator(fake_B.detach(), real_A)\n",
    "            loss_fake = criterion_GAN(pred_fake, fake)\n",
    "\n",
    "            # Total loss\n",
    "            loss_D = 0.5 * (loss_real + loss_fake)\n",
    "\n",
    "            d_scaler.scale(loss_D).backward()\n",
    "            d_scaler.step(optimizer_D)\n",
    "            d_scaler.update()\n",
    "        \n",
    "        \n",
    "        # --------------\n",
    "        #  Log Progress\n",
    "        # --------------\n",
    "        loop.set_description(f\"epoch: {epoch} loss discriminator: {loss_D:.5f} loss generator: {loss_G:.5f}\")\n",
    "        \n",
    "\n",
    "        # If at sample interval save image\n",
    "        batches_done = epoch * len(trainloader) + i\n",
    "        if batches_done % sample_interval == 0:\n",
    "            sample_images(batches_done, 10)\n",
    "          \n",
    "    # check if lr should be updated\n",
    "    val_loss_G, val_loss_D = val_loss()\n",
    "    print(f\"epoch {epoch} with G and D val loss:\", val_loss_G, val_loss_D)\n",
    "    lrs_D.step(val_loss_D)\n",
    "    lrs_G.step(val_loss_G)  \n",
    "    \n",
    "    # Save model checkpoints\n",
    "    if epoch % checkpoint_interval == 0:\n",
    "        torch.save(generator.state_dict(), \"saved_models/%s/generator_%d.pth\" % (\"watermarkdataset\", epoch))\n",
    "        torch.save(discriminator.state_dict(), \"saved_models/%s/discriminator_%d.pth\" % (\"watermarkdataset\", epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e23411c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(batches_done, N):\n",
    "    \"\"\" Save the first N generated images from the dataset \"\"\"\n",
    "    generator.eval()\n",
    "    generator.to(\"cpu\")\n",
    "    \n",
    "    imgs = []\n",
    "    for i, batch in enumerate(tqdm(valloader)):\n",
    "        if i >= N:\n",
    "            break\n",
    "        t = []\n",
    "        real_A = Variable(batch[0].type(Tensor))\n",
    "        real_B = Variable(batch[1].type(Tensor))\n",
    "        t.append(real_A.detach())\n",
    "        \n",
    "        _,_,w,h = real_A.shape\n",
    "        real_A = transforms.functional.pad(real_A, [0, 0, int((int(h/kernel_size)+1)*kernel_size)-h, int((int(w/kernel_size)+1)*kernel_size)-w])\n",
    "        real_A = unfold(real_A).squeeze(0).T.view(-1,3,kernel_size,kernel_size)\n",
    "        fake_B = generator(real_A)\n",
    "        \n",
    "        new_w = int((int(w/kernel_size)+1)*kernel_size)\n",
    "        new_h = int((int(h/kernel_size)+1)*kernel_size)\n",
    "        fake_B = fake_B.permute(1,2,3,0)\n",
    "        fake_B = fake_B.reshape(1,3*kernel_size*kernel_size,fake_B.shape[3])\n",
    "        fold = nn.Fold((new_w,new_h), (kernel_size,kernel_size), stride=(kernel_size,kernel_size))\n",
    "        fake_B = fold(fake_B)\n",
    "        \n",
    "        fake_B = fake_B[:, :, 0:w, 0:h]\n",
    "        t.append(fake_B.detach())\n",
    "        t.append(real_B.detach())\n",
    "        imgs.append(tuple(t))\n",
    "    \n",
    "    os.mkdir(f\"images/watermarkdataset/{batches_done}\")\n",
    "    for j, (a,fb,b) in enumerate(imgs):\n",
    "        img_sample = torch.cat((a, fb, b), -2)\n",
    "        save_image(img_sample, f\"images/watermarkdataset/{batches_done}/{j}.jpg\")\n",
    "    \n",
    "    generator.to(device)\n",
    "    generator.train()\n",
    "    return imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1616bc9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
